[1]  Waymo open dataset: An autonomous driving dataset, 2019.
[2]  Alexandre   Alahi,   Kratarth   Goel,   Vignesh   Ramanathan,Alexandre Robicquet, Li Fei-Fei, and Silvio Savarese.  So-cial lstm: Human trajectory prediction in crowded spaces. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 961–971, 2016.
[3]  Apratim  Bhattacharyya,  Mario  Fritz,  and  Bernt  Schiele.Long-term  on-board  prediction  of  people  in  traffic  scenesunder uncertainty.   InProceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages 4194–4202, 2018.
[4]  Fabian  Caba  Heilbron,  Victor  Escorcia,  Bernard  Ghanem,and Juan Carlos Niebles.   Activitynet:  A large-scale videobenchmark for human activity understanding.   InProceed-ings of the IEEE Conference on Computer Vision and PatternRecognition, pages 961–970, 2015.
[5]  Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora,Venice  Erin  Liong,  Qiang  Xu,  Anush  Krishnan,  Yu  Pan,Giancarlo Baldan,  and Oscar Beijbom.   nuscenes:  A mul-timodal  dataset  for  autonomous  driving.arXiv  preprintarXiv:1903.11027, 2019.
[6]  Joao  Carreira,  Eric  Noland,  Andras  Banki-Horvath,  ChloeHillier, and Andrew Zisserman. A short note about kinetics-600.arXiv preprint arXiv:1808.01340, 2018.
[7]  Joao  Carreira  and  Andrew  Zisserman.    Quo  vadis,  actionrecognition?  a new model and the kinetics dataset.  Inpro-ceedings of the IEEE Conference on Computer Vision andPattern Recognition, pages 6299–6308, 2017.
[8]  Rohan Chandra, Uttaran Bhattacharya, Aniket Bera, and Di-nesh Manocha.  Traphic:  Trajectory prediction in dense andheterogeneous traffic using weighted interactions.   InPro-ceedings of the IEEE Conference on Computer Vision andPattern Recognition, pages 8483–8492, 2019.
[9]  Ming-Fang  Chang,  John  Lambert,  Patsorn  Sangkloy,  Jag-jeet Singh, Slawomir Bak, Andrew Hartnett, De Wang, Pe-ter  Carr,  Simon  Lucey,  Deva  Ramanan,  et  al.   Argoverse:3d  tracking  and  forecasting  with  rich  maps.    InProceed-ings of the IEEE Conference on Computer Vision and PatternRecognition, pages 8748–8757, 2019.
[10]  Chiho Choi and Behzad Dariush.   Looking to relations forfuture trajectory forecast.  InProceedings of the IEEE Inter-national  Conference  on  Computer  Vision  (ICCV),  October2019.
[11]  Chiho Choi,  Abhishek Patil,  and Srikanth Malla.   Drogon:A causal reasoning framework for future trajectory forecast.arXiv preprint arXiv:1908.00024, 2019.
[12]  Dima  Damen,  Hazel  Doughty,  Giovanni  Maria  Farinella,Sanja  Fidler,  Antonino  Furnari,  Evangelos  Kazakos,  Da-vide Moltisanti,  Jonathan Munro,  Toby Perrett,  Will Price,and  Michael  Wray.    Scaling  egocentric  vision:   The  epic-kitchens dataset.  InEuropean Conference on Computer Vi-sion (ECCV), 2018.
[13]  Nachiket Deo and Mohan M Trivedi.   Multi-modal trajec-tory prediction of surrounding vehicles with maneuver basedlstms.   In2018 IEEE Intelligent Vehicles Symposium (IV),pages 1179–1184. IEEE, 2018.
[14]  Valentina Fontana, Gurkirt Singh, Stephen Akrigg, ManueleDi   Maio,   Suman   Saha,   and   Fabio   Cuzzolin.Actiondetection  from  a  robot-car  perspective.arXiv  preprintarXiv:1807.11332, 2018.
[15]  Andreas Geiger, Philip Lenz, Christoph Stiller, and RaquelUrtasun. Vision meets robotics: The kitti dataset.The Inter-national Journal of Robotics Research,  32(11):1231–1237,2013.
[16]  Chunhui Gu, Chen Sun, David A Ross, Carl Vondrick, Car-oline Pantofaru,  Yeqing Li,  Sudheendra Vijayanarasimhan,George  Toderici,  Susanna  Ricco,  Rahul  Sukthankar,  et  al.Ava:  A video dataset of spatio-temporally localized atomicvisual  actions.InProceedings  of  the  IEEE  Conferenceon Computer Vision and Pattern Recognition, pages 6047–6056, 2018.
[17]  Agrim  Gupta,  Justin  Johnson,  Li  Fei-Fei,  Silvio  Savarese,and Alexandre Alahi.   Social gan:  Socially acceptable tra-jectories with generative adversarial networks.  InProceed-ings of the IEEE Conference on Computer Vision and PatternRecognition, pages 2255–2264, 2018.
[18]  Kensho Hara,  Hirokatsu Kataoka,  and Yutaka Satoh.   Canspatiotemporal 3d cnns retrace the history of 2d cnns and im-agenet? InProceedings of the IEEE conference on ComputerVision and Pattern Recognition, pages 6546–6555, 2018.
[19]  Noureldien  Hussein,  Efstratios  Gavves,  and  Arnold  WMSmeulders.  Timeception for complex action recognition.  InProceedings  of  the  IEEE  Conference  on  Computer  Visionand Pattern Recognition, pages 254–263, 2019.
[20]  Andrej Karpathy, George Toderici, Sanketh Shetty, ThomasLeung, Rahul Sukthankar, and Li Fei-Fei. Large-scale videoclassification  with  convolutional  neural  networks.   InPro-ceedings  of  the  IEEE  conference  on  Computer  Vision  andPattern Recognition, pages 1725–1732, 2014.
[21]  Will  Kay,  Joao  Carreira,  Karen  Simonyan,  Brian  Zhang,Chloe  Hillier,  Sudheendra  Vijayanarasimhan,  Fabio  Viola,Tim Green, Trevor Back, Paul Natsev, et al. The kinetics hu-man action video dataset.arXiv preprint arXiv:1705.06950,2017.
[22]  Alex Kendall,  Yarin Gal,  and Roberto Cipolla.   Multi-tasklearning using uncertainty to weigh losses for scene geome-try and semantics.  InProceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages 7482–7491, 2018.
[23]  R. Kesten, M. Usman, J. Houston, T. Pandya, K. Nadhamuni,A.  Ferreira,  M.  Yuan,  B.  Low,  A.  Jain,  P.  Ondruska,  S.Omari, S. Shah, A. Kulkarni, A. Kazakova, C. Tao, L. Platin-sky,  W.  Jiang,  and  V.  Shet.   Lyft  level  5  av  dataset  2019.https://level5.lyft.com/dataset/, 2019.
[24]  H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre.HMDB:  a  large  video  database  for  human  motion  recog-nition.   InProceedings of the International Conference onComputer Vision (ICCV), 2011.
[25]  Tian Lan,  Tsung-Chuan Chen,  and Silvio Savarese.   A hi-erarchical  representation  for  future  action  prediction.InEuropean Conference on Computer Vision, pages 689–704.Springer, 2014.
[26]  Namhoon Lee, Wongun Choi, Paul Vernaza, Christopher BChoy, Philip HS Torr, and Manmohan Chandraker.  DesireDistant future prediction in dynamic scenes with interactingagents. InProceedings of the IEEE Conference on ComputerVision and Pattern Recognition, pages 336–345, 2017.
[27]  Alon  Lerner,  Yiorgos  Chrysanthou,  and  Dani  Lischinski.Crowds  by  example.InComputer  graphics  forum,  vol-ume 26, pages 655–664. Wiley Online Library, 2007.
[28]  Jiachen  Li,  Hengbo  Ma,  and  Masayoshi  Tomizuka.   Con-ditional generative neural system for probabilistic trajectoryprediction.  In2019 IEEE Conference on Robotics and Sys-tems (IROS), 2019.
[29]  Jiachen   Li,    Hengbo   Ma,    and   Masayoshi   Tomizuka.Interaction-aware multi-agent tracking and probabilistic be-havior prediction via adversarial learning.  In2019 IEEE In-ternational Conference on Robotics and Automation (ICRA).IEEE, 2019.
[30]  Yuexin Ma,  Xinge Zhu,  Sibo Zhang,  Ruigang Yang,  Wen-ping Wang, and Dinesh Manocha. Trafficpredict: Trajectoryprediction for heterogeneous traffic-agents.  InProceedingsof the AAAI Conference on Artificial Intelligence, volume 33,pages 6120–6127, 2019.
[31]  Srikanth  Malla  and  Chiho  Choi.Nemo:Future  ob-ject  localization  using  noisy  ego  priors.arXiv  preprintarXiv:1909.08150, 2019.
[32]  Marcin Marszałek, Ivan Laptev, and Cordelia Schmid.  Ac-tions in context.  InCVPR 2009-IEEE Conference on Com-puter Vision & Pattern Recognition, pages 2929–2936. IEEEComputer Society, 2009.
[33]  Ra ́ul   Quintero   M ́ınguez,   Ignacio   Parra   Alonso,   DavidFern ́andez-Llorca,  and  Miguel Angel  Sotelo.Pedestrianpath,  pose,  and  intention  prediction  through  gaussian  pro-cess dynamical models and pedestrian activity recognition.IEEE  Transactions  on  Intelligent  Transportation  Systems,20(5):1803–1814, 2018.
[34]  Sangmin Oh, Anthony Hoogs, Amitha Perera, Naresh Cun-toor,  Chia-Chih Chen,  Jong Taek Lee,  Saurajit Mukherjee,JK Aggarwal,  Hyungtae Lee,  Larry Davis,  et al.   A large-scale benchmark dataset for event recognition in surveillancevideo. InCVPR 2011, pages 3153–3160. IEEE, 2011.
[35]  Seong  Hyeon  Park,  ByeongDo  Kim,  Chang  Mook  Kang,Chung  Choo  Chung,  and  Jun  Won  Choi.Sequence-to-sequence prediction of vehicle trajectory via lstm encoder-decoder architecture. In2018 IEEE Intelligent Vehicles Sym-posium (IV), pages 1672–1678. IEEE, 2018.
[36]  Abhishek Patil, Srikanth Malla, Haiming Gang, and Yi-TingChen.  The h3d dataset for full-surround 3d multi-object de-tection and tracking in crowded urban scenes.arXiv preprintarXiv:1903.01568, 2019.
[37]  Stefano Pellegrini, Andreas Ess, and Luc Van Gool. Improv-ing data association by joint modeling of pedestrian trajec-tories and groupings.  InEuropean conference on computervision, pages 452–465. Springer, 2010.
[38]  Amir  Rasouli,  Iuliia  Kotseruba,  Toni  Kunic,  and  John  K.Tsotsos.   Pie:  A large-scale dataset and models for pedes-trian intention estimation and trajectory prediction.   InTheIEEE International Conference on Computer Vision (ICCV),October 2019.
[39]  Amir Rasouli,  Iuliia Kotseruba,  and John K Tsotsos.   Arethey going to cross?  a benchmark dataset and baseline forpedestrian crosswalk behavior.  InProceedings of the IEEEInternational Conference on Computer Vision,  pages 206–213, 2017.
[40]  Nicholas Rhinehart, Kris M Kitani, and Paul Vernaza. R2p2:A  reparameterized  pushforward  policy  for  diverse,  precisegenerative path forecasting. InProceedings of the EuropeanConference  on  Computer  Vision  (ECCV),  pages  772–788,2018.
[41]  Alexandre  Robicquet,  Amir  Sadeghian,  Alexandre  Alahi,and Silvio Savarese.  Learning social etiquette:  Human tra-jectory understanding in crowded scenes.  InEuropean con-ference on computer vision, pages 549–565. Springer, 2016.
[42]  Christoph  Scholler,  Vincent  Aravantinos,  Florian  Lay,  andAlois   Knoll.The   simpler   the   better:Constant   ve-locity  for  pedestrian  motion  prediction.arXiv  preprintarXiv:1903.07933, 2019.
[43]  Gunnar  A.  Sigurdsson,  Goul  Varol,  Xiaolong  Wang,  AliFarhadi,  Ivan  Laptev,  and  Abhinav  Gupta.   Hollywood  inhomes:   Crowdsourcing  data  collection  for  activity  under-standing.InEuropean  Conference  on  Computer  Vision,2016.
[44]  Karen Simonyan and Andrew Zisserman.  Two-stream con-volutional networks for action recognition in videos.  InAd-vances in neural information processing systems, pages 568–576, 2014.
[45]  Gurkirt Singh, Suman Saha, and Fabio Cuzzolin.  Predictingaction tubes. InProceedings of the European Conference onComputer Vision (ECCV), pages 0–0, 2018.
[46]  Gurkirt  Singh,  Suman  Saha,  Michael  Sapienza,  Philip  HSTorr,  and  Fabio  Cuzzolin.   Online  real-time  multiple  spa-tiotemporal action localisation and prediction.  InProceed-ings of the IEEE International Conference on Computer Vi-sion, pages 3637–3646, 2017.
[47]  Khurram Soomro, Haroon Idrees, and Mubarak Shah.  Pre-dicting the where and what of actors and actions through on-line action localization.   InProceedings of the IEEE Con-ference on Computer Vision and Pattern Recognition, pages2648–2657, 2016.
[48]  Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah.Ucf101: A dataset of 101 human actions classes from videosin the wild.arXiv preprint arXiv:1212.0402, 2012.
[49]  Chen Sun, Abhinav Shrivastava, Carl Vondrick, Kevin Mur-phy, Rahul Sukthankar, and Cordelia Schmid.  Actor-centricrelation network.   InProceedings of the European Confer-ence on Computer Vision (ECCV), pages 318–334, 2018.
[50]  Chen Sun, Abhinav Shrivastava, Carl Vondrick, Rahul Suk-thankar, Kevin Murphy, and Cordelia Schmid. Relational ac-tion forecasting.  InProceedings of the IEEE Conference onComputer Vision and Pattern Recognition,  pages 273–283,2019.
[51]  Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani,and Manohar Paluri.  Learning spatiotemporal features with3d convolutional networks. InProceedings of the IEEE inter-national conference on computer vision, pages 4489–4497,2015.
[52]  Gul  Varol,   Ivan  Laptev,   and  Cordelia  Schmid.Long-term  temporal  convolutions  for  action  recognition.IEEEtransactions  on  pattern  analysis  and  machine  intelligence,40(6):1510–1517, 2017.
[53]  Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-reit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and IlliaPolosukhin. Attention is all you need. InAdvances in neuralinformation processing systems, pages 5998–6008, 2017.
[54]  Anirudh Vemula, Katharina Muelling, and Jean Oh.  Socialattention:  Modeling  attention  in  human  crowds.   In2018IEEE International Conference on Robotics and Automation(ICRA), pages 1–7. IEEE, 2018.
[55]  Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaim-ing He.  Non-local neural networks.  InProceedings of theIEEE Conference on Computer Vision and Pattern Recogni-tion, pages 7794–7803, 2018.
[56]  Yanyu Xu, Zhixin Piao, and Shenghua Gao. Encoding crowdinteraction with deep neural network for pedestrian trajec-tory  prediction.    InProceedings  of  the  IEEE  Conferenceon Computer Vision and Pattern Recognition, pages 5275–5284, 2018.
[57]  Hao Xue, Du Q Huynh, and Mark Reynolds.  Ss-lstm: A hi-erarchical lstm model for pedestrian trajectory prediction. In2018 IEEE Winter Conference on Applications of ComputerVision (WACV), pages 1186–1194. IEEE, 2018.
[58]  Yu Yao, Mingze Xu, Chiho Choi, David J Crandall, Ella MAtkins,  and  Behzad  Dariush.   Egocentric  vision-based  fu-ture vehicle localization for intelligent driving assistance sys-tems. In2019 International Conference on Robotics and Au-tomation (ICRA), pages 9711–9717. IEEE, 2019.
[59]  Serena Yeung, Olga Russakovsky, Ning Jin, Mykhaylo An-driluka, Greg Mori, and Li Fei-Fei.  Every moment counts:Dense detailed labeling of actions in complex videos.In-ternational Journal of Computer Vision, 126(2-4):375–389,2018.
[60]  Pu Zhang, Wanli Ouyang, Pengfei Zhang, Jianru Xue, andNanning Zheng.  Sr-lstm:  State refinement for lstm towardspedestrian trajectory prediction.  InProceedings of the IEEEConference  on  Computer  Vision  and  Pattern  Recognition,pages 12085–12094, 2019.
